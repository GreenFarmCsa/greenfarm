{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['username', 'community_id', 'location', 'carbon_credit',\n",
      "       'carbon_medals', 'comment_products', 'product_id', 'farm_id',\n",
      "       'plantername', 'product_name', 'category', 'price',\n",
      "       'carbon_credit_needed', 'number', 'sale_number', 'identifications',\n",
      "       'carbon_emission', 'donate_amount', 'create_time', 'modify_time',\n",
      "       'recommend'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "if os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n",
    "    endpoint_9e53905096384939a3b02eee24cc81a3 = 'https://s3.us.cloud-object-storage.appdomain.cloud'\n",
    "else:\n",
    "    endpoint_9e53905096384939a3b02eee24cc81a3 = 'https://s3.private.us.cloud-object-storage.appdomain.cloud'\n",
    "\n",
    "client_9e53905096384939a3b02eee24cc81a3 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='Your api key',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=endpoint_9e53905096384939a3b02eee24cc81a3)\n",
    "\n",
    "body = client_9e53905096384939a3b02eee24cc81a3.get_object(Bucket='jupiterenergypaymentplancampaign-donotdelete-pr-4mtst9zqeqmfqs',Key='product_recommendation.csv.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "product_recommendation_data = pd.read_csv(body)\n",
    "product_recommendation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.api.types as tp\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "only select province/state from location data\n",
    "'''\n",
    "def preprocessing_location(csv_data):\n",
    "    for i, row in csv_data.iterrows():\n",
    "        user_location = row['location']\n",
    "        state = user_location.split('/')[-1]\n",
    "        csv_data.at[i, 'location'] =  state\n",
    "    return csv_data\n",
    "\n",
    "'''\n",
    "count all category values for a column \n",
    "'''\n",
    "def aggregate_data(csv_data, header):\n",
    "    res = set()\n",
    "    for i, row in csv_data.iterrows():\n",
    "        data = row[header]\n",
    "        if type(data) == float and pd.isna(data):\n",
    "            continue\n",
    "        category = data.split('/')\n",
    "        for c in category:\n",
    "            res.add(c)\n",
    "        row[header] = category\n",
    "    res = sorted(list(set(res)))\n",
    "    return res, csv_data\n",
    "\n",
    "'''\n",
    "count location value frequency\n",
    "'''\n",
    "def aggregate_location(csv_data, header):\n",
    "    res = {}\n",
    "    count = 0\n",
    "    for i, row in csv_data.iterrows():\n",
    "        data = row[header]\n",
    "        if data not in res.keys():\n",
    "            res[data] = count\n",
    "            count += 1\n",
    "    return res\n",
    "\n",
    "'''\n",
    "only select the first six number for date time\n",
    "'''\n",
    "def preprocess_date(csv_data):\n",
    "    for i, row in csv_data.iterrows():\n",
    "        data = row['create_time']\n",
    "        modify_time = row['modify_time']\n",
    "        data = data[0:8]\n",
    "        modify_time = modify_time[0:8]\n",
    "        csv_data.at[i, 'create_time'] = data\n",
    "        csv_data.at[i, 'modify_time'] = modify_time\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_data = preprocessing_location(product_recommendation_data)\n",
    "location_dictionary = aggregate_location(csv_data, 'location')\n",
    "community, csv_data = aggregate_data(csv_data, 'community_id')\n",
    "comment_product, csv_data = aggregate_data(csv_data, 'comment_products')\n",
    "medals, csv_data = aggregate_data(csv_data, 'carbon_medals')\n",
    "products, csv_data = aggregate_data(csv_data, 'product_name')\n",
    "category_dictionary = aggregate_location(csv_data, 'category')\n",
    "identifications, csv_data = aggregate_data(csv_data, 'identifications')\n",
    "csv_data = preprocess_date(csv_data)\n",
    "product_dictionary = aggregate_location(csv_data, 'product_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "one_hot_encoding algorithm\n",
    "'''\n",
    "def one_hot_encoding(list_data, aggregate_data):\n",
    "    encoding = \"\"\n",
    "    if type(list_data) == float and pd.isna(list_data):\n",
    "        return encoding\n",
    "    for element in aggregate_data:\n",
    "        if element in list_data:\n",
    "            encoding = encoding + '1'\n",
    "        else:\n",
    "            encoding = encoding + '0'\n",
    "    return int(encoding)\n",
    "\n",
    "'''\n",
    "apply one-hot-encoding to given column\n",
    "'''\n",
    "def apply_encoding(csv_data, header, aggregate):\n",
    "    for i, row in csv_data.iterrows():\n",
    "        raw = row[header]\n",
    "        encoding = one_hot_encoding(raw, aggregate)\n",
    "        csv_data.at[i, header] = encoding\n",
    "    return csv_data\n",
    "\n",
    "'''\n",
    "apply one-hot-encoding to location column\n",
    "'''\n",
    "def apply_location_encoding(csv_data):\n",
    "    for i, row in csv_data.iterrows():\n",
    "        location = row['location']\n",
    "        csv_data.at[i, 'location'] = location_dictionary[location]\n",
    "    return csv_data\n",
    "\n",
    "'''\n",
    "apply one-hot-encoding to category column\n",
    "'''\n",
    "def apply_category_encoding(csv_data):\n",
    "    for i, row in csv_data.iterrows():\n",
    "        category = row['category']\n",
    "        csv_data.at[i, 'category'] = category_dictionary[category]\n",
    "    return csv_data\n",
    "\n",
    "'''\n",
    "standardize numerical variable\n",
    "'''\n",
    "def standardlize(csv_data, header):\n",
    "    mean = csv_data[header].mean()\n",
    "    sd = csv_data[header].std()\n",
    "    for i, row in csv_data.iterrows():\n",
    "        rent = row[header]\n",
    "        standard = (rent - mean) / sd\n",
    "        csv_data.at[i, header] = standard\n",
    "    return csv_data\n",
    "\n",
    "'''\n",
    "fill missing values with mode\n",
    "'''\n",
    "def fill_with_mode(csv_data, community_mode, medals_mode, comment_mode, location_mode):\n",
    "    for i, row in csv_data.iterrows():\n",
    "        if row['community_id'] == '':\n",
    "            csv_data.at[i, 'community_id'] = community_mode\n",
    "        if row['carbon_medals'] == '':\n",
    "            csv_data.at[i, 'carbon_medals'] = medals_mode\n",
    "        if row['comment_products'] == '':\n",
    "            csv_data.at[i, 'comment_products'] = comment_mode\n",
    "        if row['location'] == '':\n",
    "            csv_data.at[i, 'location'] = location_mode\n",
    "    return csv_data\n",
    "\n",
    "'''\n",
    "apply one-hot-encoding to product column\n",
    "'''\n",
    "def apply_identification_encoding(csv_data):\n",
    "    for i, row in csv_data.iterrows():\n",
    "        category = row['identifications']\n",
    "        csv_data.at[i, 'identifications'] = identification_dictionary[category]\n",
    "    return csv_data\n",
    "\n",
    "'''\n",
    "apply one-hot-encoding to product column\n",
    "'''\n",
    "def apply_product_encoding(csv_data):\n",
    "    for i, row in csv_data.iterrows():\n",
    "        category = row['product_name']\n",
    "        csv_data.at[i, 'product_name'] = product_dictionary[category]\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = apply_encoding(csv_data, 'community_id', community) \n",
    "csv_data = apply_encoding(csv_data, 'carbon_medals', medals)\n",
    "csv_data = apply_encoding(csv_data, 'comment_products', comment_product)\n",
    "csv_data = apply_encoding(csv_data, 'identifications', identifications)\n",
    "csv_data = apply_location_encoding(csv_data)\n",
    "csv_data = apply_category_encoding(csv_data)\n",
    "csv_data = apply_product_encoding(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_mode = 0\n",
    "medals_mode = 0\n",
    "comment_mode = 0\n",
    "location_mode = csv_data['location'].mode()\n",
    "csv_data = fill_with_mode(csv_data, community_mode, medals_mode, comment_mode, location_mode)\n",
    "csv_data['community_id'] = csv_data['community_id'].astype(int)\n",
    "csv_data['location'] = csv_data['location'].astype(int)\n",
    "csv_data['comment_products'] = csv_data['comment_products'].astype(int)\n",
    "csv_data['carbon_medals'] = csv_data['carbon_medals'].astype(int)\n",
    "csv_data['create_time'] = csv_data['create_time'].astype(int)\n",
    "csv_data['modify_time'] = csv_data['modify_time'].astype(int)\n",
    "\n",
    "csv_data['product_name'] = csv_data['product_name'].astype(int)\n",
    "csv_data['category'] = csv_data['category'].astype(int)\n",
    "csv_data['identifications'] = csv_data['identifications'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "def train_model(csv_data, test_size, random_state):\n",
    "    Y = csv_data['recommend']\n",
    "    csv_data = csv_data.drop(['recommend', 'username', 'plantername'], axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(csv_data, Y, test_size = test_size, random_state = random_state)\n",
    "    model = XGBClassifier(objective = 'binary:logitraw')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, X_train\n",
    "model, X_train = train_model(csv_data, 0.33, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\": 'Your api key',\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create client to access our WML service\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "def save_model(model):\n",
    "    wml_credentials = {\n",
    "    \"apikey\": 'Your api key',\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "    }\n",
    "    client = APIClient(wml_credentials)\n",
    "    software_spec_uid = client.software_specifications.get_id_by_name(\"default_py3.7\")\n",
    "    space_id = 'Your space id'\n",
    "    client.set.default_space(space_id)\n",
    "    metadata = {\n",
    "                client.repository.ModelMetaNames.NAME: 'Gradient Boosting model to predict product recommendation score',\n",
    "                client.repository.ModelMetaNames.TYPE: 'scikit-learn_0.23',\n",
    "                client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "    }\n",
    "    published_model = client.repository.store_model(\n",
    "        model=model,\n",
    "        meta_props=metadata)\n",
    "    return published_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model = save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "aggregate on product and user purchase relationship\n",
    "'''\n",
    "def get_user_farm_dict(gf_rent):\n",
    "    user_product_dic = {}\n",
    "    product_dic = {}\n",
    "    product_sequence = 0\n",
    "    for i, row in gf_rent.iterrows():\n",
    "        product = row['product_id']\n",
    "        user = row['username']\n",
    "        if user not in user_product_dic.keys():\n",
    "            user_product_dic[user] = []\n",
    "        user_product_dic[user].append(product)\n",
    "        if product not in product_dic.keys():\n",
    "            product_dic[product] = product_sequence\n",
    "            product_sequence = product_sequence + 1\n",
    "    return user_product_dic, product_dic\n",
    "\n",
    "def get_user_matrix(user_product_dic, gf_order_data, products):\n",
    "    num_user = len(user_product_dic.keys())\n",
    "    num_product = len(products.keys())\n",
    "    user_sequence = 0\n",
    "    user_dic = {}\n",
    "    user_product_matrix = np.ndarray(shape = (num_user, num_product), dtype = int)\n",
    "    user_product_matrix.fill(0)\n",
    "    for user in user_product_dic.keys():\n",
    "        for f in user_product_dic[user]:\n",
    "            product_number = products[f]\n",
    "            user_product_matrix[user_sequence][product_number] = 1\n",
    "        user_dic[user] = user_sequence\n",
    "        user_sequence = user_sequence + 1\n",
    "    return user_product_matrix, user_dic\n",
    "\n",
    "'''\n",
    "calculate cosine similarity\n",
    "'''\n",
    "def calculate_similarity(user_product_matrix):\n",
    "    return sklearn.metrics.pairwise.cosine_similarity(user_product_matrix)\n",
    "\n",
    "'''\n",
    "calculate user similarity\n",
    "'''\n",
    "def get_similar_user(given_user, user_product_matrix, user_dic):\n",
    "    user = user_dic[given_user]\n",
    "    user_matrix = user_product_matrix[user]\n",
    "    sim_dic = {}\n",
    "    similarity_score = calculate_similarity(user_product_matrix)[user]\n",
    "    for i in range(0, len(similarity_score)):\n",
    "        if i != user:\n",
    "            score = similarity_score[i]\n",
    "            if score not in sim_dic:\n",
    "                sim_dic[score] = []\n",
    "            sim_dic[score].append(i)\n",
    "    sorted_similarity_score = sorted(sim_dic.keys(), reverse = True)\n",
    "    similar_user = []\n",
    "    for i in range(0, min(3, len(sorted_similarity_score))):\n",
    "        score = sorted_similarity_score[i]\n",
    "        for j in range(0, len(sim_dic[score])):\n",
    "            similar_user.append(sim_dic[score][j])\n",
    "    return similar_user\n",
    "\n",
    "'''\n",
    "recall set of products\n",
    "'''\n",
    "def get_recall_set(user_farm_matrix, similar_user, given_user, user_dic):\n",
    "    product_not_buy = []\n",
    "    user_number = user_dic[given_user]\n",
    "    for user in similar_user:\n",
    "        user_matrix = user_farm_matrix[user]\n",
    "        for i in range(0, len(user_matrix)):\n",
    "            purchase = user_matrix[i]\n",
    "            user_purchase= user_farm_matrix[user_number][i]\n",
    "            if user_purchase == 0 and purchase == 1:\n",
    "                product_not_buy.append(i)\n",
    "    return product_not_buy \n",
    "'''\n",
    "check if the given user has purchase history\n",
    "'''\n",
    "def check_user_purchase(gf_order, given_user):\n",
    "    user_order = gf_order[gf_order['username'] == given_user]\n",
    "    #need to check if the cell is NA/null/empty string\n",
    "    if not user_order['order_id'].empty:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>username</th>\n",
       "      <th>product_id</th>\n",
       "      <th>address</th>\n",
       "      <th>money</th>\n",
       "      <th>carbon_credit</th>\n",
       "      <th>create_time</th>\n",
       "      <th>modify_time</th>\n",
       "      <th>remark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234</td>\n",
       "      <td>feho</td>\n",
       "      <td>15</td>\n",
       "      <td>New York/NY</td>\n",
       "      <td>200</td>\n",
       "      <td>121</td>\n",
       "      <td>2021062811</td>\n",
       "      <td>2021062813</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5678</td>\n",
       "      <td>kct</td>\n",
       "      <td>52</td>\n",
       "      <td>San Jose/CA</td>\n",
       "      <td>600</td>\n",
       "      <td>200</td>\n",
       "      <td>2021062812</td>\n",
       "      <td>2021062816</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8372</td>\n",
       "      <td>beq</td>\n",
       "      <td>55</td>\n",
       "      <td>Paris/France</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>2021062812</td>\n",
       "      <td>2021062816</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8373</td>\n",
       "      <td>beq</td>\n",
       "      <td>15</td>\n",
       "      <td>Paris/France</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>2021062818</td>\n",
       "      <td>2021062820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id username  product_id       address  money  carbon_credit  \\\n",
       "0      1234     feho          15   New York/NY    200            121   \n",
       "1      5678      kct          52   San Jose/CA    600            200   \n",
       "2      8372      beq          55  Paris/France    200             60   \n",
       "3      8373      beq          15  Paris/France    100            100   \n",
       "\n",
       "   create_time  modify_time  remark  \n",
       "0   2021062811   2021062813     NaN  \n",
       "1   2021062812   2021062816     NaN  \n",
       "2   2021062812   2021062816     NaN  \n",
       "3   2021062818   2021062820     NaN  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "body = client_9e53905096384939a3b02eee24cc81a3.get_object(Bucket='jupiterenergypaymentplancampaign-donotdelete-pr-4mtst9zqeqmfqs',Key='gf_order.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "gf_order = pd.read_csv(body)\n",
    "gf_order.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "user_product_dic, products = get_user_farm_dict(gf_order)\n",
    "user_product_matrix, user_dic = get_user_matrix(user_product_dic, gf_order, products)\n",
    "similar_user = get_similar_user('feho', user_product_matrix, user_dic)\n",
    "product_not_purchase = get_recall_set(user_product_matrix, similar_user, 'feho', user_dic)\n",
    "\n",
    "pd_index = []\n",
    "for index in product_not_purchase:\n",
    "    pd_index.append(gf_order.iloc[index])\n",
    "product_predict_set = pd.DataFrame(pd_index, columns = gf_order.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_id_index(gf_order):\n",
    "    dic = {}\n",
    "    for i, row in gf_order.iterrows():\n",
    "        dic[i] = row['product_id']\n",
    "    return dic\n",
    "product_id_index = product_id_index(gf_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = {'username': 'aaa', 'community_id': 'c1/c2', 'location': 'New York/NY', 'carbon_credit': '589', 'carbon_medals': 'm1/m2', 'comment_products': 'p1'}\n",
    "test_user = pd.DataFrame(test_user, index = [0])\n",
    "\n",
    "def change_index(csv_data1, product_not_purchase) :\n",
    "    csv_data = csv_data1.rename(mapper = {csv_data1.index.values[0]: product_not_purchase}, axis = 0)\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = product_not_purchase[0]\n",
    "csv_data1 = change_index(test_user, index)\n",
    "product = pd.DataFrame([product_predict_set.loc[index]], columns = gf_order.columns)\n",
    "product_id = product['product_id']\n",
    "recommendation = csv_data.loc[csv_data['product_id'] == int(product_id), 'product_id']\n",
    "df = csv_data[csv_data['product_id'].isin(recommendation)]\n",
    "df = change_index(df, index)\n",
    "df = df.drop(['username', 'community_id', 'location', 'carbon_credit', 'carbon_medals', 'comment_products'], axis = 1)\n",
    "concate_rows = pd.concat([csv_data1, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data1 = preprocessing_location(concate_rows)\n",
    "location_dictionary = aggregate_location(csv_data1, 'location')\n",
    "community, csv_data1 = aggregate_data(csv_data1, 'community_id')\n",
    "comment_product, csv_data1 = aggregate_data(csv_data1, 'comment_products')\n",
    "medals, csv_data1 = aggregate_data(csv_data1, 'carbon_medals')\n",
    "category_dictionary = aggregate_location(csv_data1, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data1 = apply_encoding(csv_data1, 'community_id', community) \n",
    "csv_data1 = apply_encoding(csv_data1, 'carbon_medals', medals)\n",
    "csv_data1 = apply_encoding(csv_data1, 'comment_products', comment_product)\n",
    "csv_data1 = apply_location_encoding(csv_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_type(csv_data):\n",
    "    community_mode = 0\n",
    "    medals_mode = 0\n",
    "    comment_mode = 0\n",
    "    location_mode = csv_data['location'].mode()\n",
    "    csv_data = fill_with_mode(csv_data, community_mode, medals_mode, comment_mode, location_mode)\n",
    "    csv_data['community_id'] = csv_data['community_id'].astype(int)\n",
    "    csv_data['location'] = csv_data['location'].astype(int)\n",
    "    csv_data['comment_products'] = csv_data['comment_products'].astype(int)\n",
    "    csv_data['carbon_medals'] = csv_data['carbon_medals'].astype(int)\n",
    "    csv_data['carbon_credit'] = csv_data['carbon_credit'].astype(int)\n",
    "    csv_data['create_time'] = csv_data['create_time'].astype(int)\n",
    "    csv_data['modify_time'] = csv_data['modify_time'].astype(int)\n",
    "\n",
    "    csv_data['product_name'] = csv_data['product_name'].astype(int)\n",
    "    csv_data['category'] = csv_data['category'].astype(int)\n",
    "    csv_data['identifications'] = csv_data['identifications'].astype(int)\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data1 = int_type(csv_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data1 = csv_data1.drop(['username', 'plantername', 'recommend'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.1496055  -0.14960556]]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_proba(csv_data1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_farm(prediction, farm_not_rent):\n",
    "    farm_score = {}\n",
    "    for i in range(0, len(prediction)):\n",
    "        pred_score = prediction[i]\n",
    "        if pred_score[1] > pred_score[0]:\n",
    "            farm_score[farm_not_rent[i]] = pred_score[1]\n",
    "    sorted_farm_score = [key for key, value in sorted(farm_score.items(), key=lambda i: i[1], reverse=True)]\n",
    "    return sorted_farm_score\n",
    "\n",
    "sorted_farm_score = sort_farm(prediction, product_not_purchase)\n",
    "def farm_recommendation(sorted_farm_score):\n",
    "    count = 0\n",
    "    recommended_farm = []\n",
    "    for farm in sorted_farm_score:\n",
    "        if count < 2:\n",
    "            recommended_farm.append(product_id_index[farm])\n",
    "            count += 1\n",
    "    return recommended_farm\n",
    "def feature():\n",
    "    im=pd.DataFrame({'importance':model.feature_importances_})\n",
    "    im=im.sort_values(by='importance',ascending=False)\n",
    "    feature_index = im.index[0:3]\n",
    "    features = [X_train.columns[x] for x in feature_index]\n",
    "    return features"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d02c74a55b3621ca9dac662824742444a2b651af61feff78836515c90c3b90b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
